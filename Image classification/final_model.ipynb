{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import math as math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import BatchNormalization\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.regularizers import l2\n",
    "from PIL import Image"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "print(tf.__version__)"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "import logging\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "tf.get_logger().setLevel('INFO')\n",
    "tf.autograph.set_verbosity(0)\n",
    "\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Dataset folders \n",
    "dataset_dir = '../input/flippeddataset2/training_data_final_divided_and_flipped2'\n",
    "training_dir  = os.path.join(dataset_dir, 'Training')\n",
    "validation_dir = os.path.join(dataset_dir, 'Validation')\n",
    "#test_dir = os.path.join(dataset_dir, 'test')"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Plot example images from dataset\n",
    "labels = ['Species1',       # 0\n",
    "          'Species2',       # 1\n",
    "          'Species3',       # 2\n",
    "          'Species4',       # 3\n",
    "          'Species5',       # 4\n",
    "          'Species6',       # 5\n",
    "          'Species7',       # 6\n",
    "          'Species8',       # 7\n",
    "          ]  "
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "input_shape = (96, 96, 3)"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from keras.applications.efficientnet import preprocess_input, EfficientNetB4\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_gen = ImageDataGenerator(rotation_range=45,\n",
    "                                        height_shift_range=0.3,\n",
    "                                        width_shift_range=0.3,\n",
    "                                        zoom_range=0.4,\n",
    "                                        vertical_flip=True, \n",
    "                                        brightness_range=[0.2,1.2],\n",
    "                                        fill_mode='reflect',\n",
    "                                        preprocessing_function=preprocess_input)\n",
    "\n",
    "\n",
    "train_gen = train_data_gen.flow_from_directory(directory=training_dir,\n",
    "                                               target_size=(96,96),\n",
    "                                               color_mode='rgb',\n",
    "                                               classes=labels,\n",
    "                                               class_mode='categorical',\n",
    "                                               batch_size=16,\n",
    "                                               shuffle=True,\n",
    "                                               seed=seed)\n",
    "valid_data_gen = ImageDataGenerator(preprocessing_function=preprocess_input)#, rescale=1/255.)\n",
    "\n",
    "valid_gen = train_data_gen.flow_from_directory(directory=validation_dir,\n",
    "                                               target_size=(96,96),\n",
    "                                               color_mode='rgb',\n",
    "                                               classes=labels,\n",
    "                                               class_mode='categorical',\n",
    "                                               batch_size=16,\n",
    "                                               shuffle=False,\n",
    "                                               seed=seed)"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter(train_gen.classes)                          \n",
    "max_val = float(max(counter.values()))       \n",
    "class_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}          \n",
    "\n",
    "class_weights"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "supernet = EfficientNetB4(include_top=False,\n",
    "                        weights='imagenet',\n",
    "                        input_shape=(380,380,3))\n",
    "\n",
    "supernet.trainable = False\n",
    "\n",
    "last_nonTrainable_layer = 10\n",
    "for i, layer in enumerate(supernet.layers[:last_nonTrainable_layer]):\n",
    "  layer.trainable=False\n",
    "\n",
    "for i, layer in enumerate(supernet.layers):\n",
    "   print(i, layer.name, layer.trainable)"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Utility function to create folders and callbacks for training\n",
    "from datetime import datetime\n",
    "\n",
    "def create_folders_and_callbacks(model_name):\n",
    "\n",
    "  exps_dir = os.path.join('data_augmentation_experiments')\n",
    "  if not os.path.exists(exps_dir):\n",
    "      os.makedirs(exps_dir)\n",
    "\n",
    "  now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "\n",
    "  exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
    "  if not os.path.exists(exp_dir):\n",
    "      os.makedirs(exp_dir)\n",
    "      \n",
    "  callbacks = []\n",
    "  \"\"\"\n",
    "  # Model checkpoint\n",
    "  # ----------------\n",
    "  ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
    "  if not os.path.exists(ckpt_dir):\n",
    "      os.makedirs(ckpt_dir)\n",
    "\n",
    "  ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'), \n",
    "                                                     save_weights_only=False, # True to save only weights\n",
    "                                                     save_best_only=False) # True to save only the best epoch \n",
    "  callbacks.append(ckpt_callback)\n",
    "\n",
    "  # Visualize Learning on Tensorboard\n",
    "  # ---------------------------------\n",
    "  tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
    "  if not os.path.exists(tb_dir):\n",
    "      os.makedirs(tb_dir)\n",
    "      \n",
    "  # By default shows losses and metrics for both training and validation\n",
    "  tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir, \n",
    "                                               profile_batch=0,\n",
    "                                               histogram_freq=1)  # if > 0 (epochs) shows weights histograms\n",
    "  callbacks.append(tb_callback)\n",
    "  \"\"\"\n",
    "  # Early Stopping\n",
    "  # --------------\n",
    "  es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "               \n",
    "  callbacks.append(es_callback)\n",
    "\n",
    "  # reduce learning rate on plateau\n",
    "\n",
    "  plat_callbacks=tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.5, min_lr=1e-5)\n",
    "  \n",
    "  callbacks.append(plat_callbacks)           \n",
    "\n",
    "  return callbacks"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Use the supernet as feature extractor\n",
    "\n",
    "inputs = tfk.Input(shape=input_shape)\n",
    "\n",
    "x = tfk.layers.Resizing(380,380, interpolation='bilinear', crop_to_aspect_ratio=True)(inputs)\n",
    "\n",
    "x = supernet(x)\n",
    "\n",
    "glob_pooling = tfkl.GlobalAveragePooling2D(name='GlobalPooling')(x)\n",
    "\n",
    "x = tfkl.Dense(\n",
    "    512,\n",
    "    kernel_initializer = tfk.initializers.GlorotUniform(seed),\n",
    ")(glob_pooling)\n",
    "\n",
    "leaky_relu_layer = tfkl.LeakyReLU()(x)\n",
    "\n",
    "leaky_relu_layer = tfkl.BatchNormalization()(leaky_relu_layer)\n",
    "\n",
    "x = tfkl.Dropout(0.2, seed=seed)(leaky_relu_layer)\n",
    "\n",
    "y = tfkl.Dense(\n",
    "    256,\n",
    "    kernel_initializer = tfk.initializers.GlorotUniform(seed),\n",
    ")(x)\n",
    "\n",
    "leaky_relu_layer2 = tfkl.LeakyReLU()(y)\n",
    "\n",
    "leaky_relu_layer2 = tfkl.BatchNormalization()(leaky_relu_layer2)\n",
    "\n",
    "leaky_relu_layer2 = tfkl.Dropout(0.3, seed=seed)(leaky_relu_layer2)\n",
    "\n",
    "outputs = tfkl.Dense(\n",
    "    8, \n",
    "    activation='softmax',\n",
    "    kernel_initializer = tfk.initializers.GlorotUniform(seed),\n",
    ")(x)\n",
    "\n",
    "\n",
    "# Connect input and output through the Model class\n",
    "ft_model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n",
    "\n",
    "# Compile the model\n",
    "ft_model.compile(loss=tfk.losses.CategoricalCrossentropy(),  \n",
    "                 optimizer=tfk.optimizers.Adam(learning_rate=1e-2), \n",
    "                 metrics=['accuracy'])\n",
    "ft_model.summary()"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "callbacks = create_folders_and_callbacks(model_name='transferLearningModel')\n",
    "\n",
    "tl_history = ft_model.fit(\n",
    "    x = train_gen,\n",
    "    batch_size = 16,\n",
    "    epochs = 200,\n",
    "    validation_data = valid_gen,\n",
    "    class_weight = class_weights,\n",
    "    callbacks = callbacks\n",
    ").history\n",
    "\n"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ft_model.save(\"efficientNetB4_tl\")"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "supernet.trainable = True"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "last_nonTrainable_layer = 185\n",
    "for i, layer in enumerate(supernet.layers[:last_nonTrainable_layer]):\n",
    "  layer.trainable=False\n",
    "\n",
    "for i, layer in enumerate(supernet.layers):\n",
    "   print(i, layer.name, layer.trainable)"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ft_model.compile(loss=tfk.losses.CategoricalCrossentropy(),  \n",
    "                 optimizer=tfk.optimizers.Adam(learning_rate=1e-4), \n",
    "                 metrics=['accuracy'])"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "callbacks = create_folders_and_callbacks(model_name='fineTunedModel')\n",
    "\n",
    "ft_history = ft_model.fit(\n",
    "    x = train_gen,\n",
    "    batch_size = 16,\n",
    "    epochs = 200,\n",
    "    validation_data = valid_gen,\n",
    "    class_weight = class_weights,\n",
    "    callbacks = callbacks\n",
    ").history\n"
   ],
   "metadata": {
    "_kg_hide-output": true,
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ft_model.save(\"efficientNetB4_ft\")"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_next_batch(generator):\n",
    "    return next(generator)"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for i in range(0,20):\n",
    "    batch = get_next_batch(valid_gen)\n",
    "\n",
    "    choosen_pos = 7\n",
    "\n",
    "    predictions = ft_model.predict(batch[0])\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "    fig.set_size_inches(15,5)\n",
    "    ax1.imshow(np.uint8(batch[0][choosen_pos]))\n",
    "    ax1.set_title('True label: '+ labels[np.argmax(batch[-1][choosen_pos])])\n",
    "    ax2.barh(list(labels), predictions[choosen_pos], color=plt.get_cmap('Paired').colors)\n",
    "    ax2.set_title('Predicted label: '+labels[np.argmax(predictions[choosen_pos])])\n",
    "    ax2.grid(alpha=.3)\n",
    "    plt.show()"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "true_label = batch[1]\n",
    "pred_label = ft_model.predict(batch[0])\n",
    "for i in range(0,500):\n",
    "    batch = get_next_batch(valid_gen)\n",
    "    true_label = np.concatenate((true_label, batch[1]), axis=0)\n",
    "    pred_label = np.concatenate((pred_label, ft_model.predict(batch[0])), axis=0)"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#confusion matrix\n",
    "cm = confusion_matrix(np.argmax(true_label, axis=-1), np.argmax(pred_label, axis=-1))\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(cm/sum(true_label), xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('True labels')\n",
    "plt.ylabel('Predicted labels')\n",
    "plt.show()"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.plot(tl_history['loss'],label = 'Training Loss', alpha=.3, color='#4D61E2', linestyle='--')\n",
    "plt.plot(tl_history['val_loss'], label='Validation Loss', alpha=.8, color='#4D61E2')\n",
    "plt.plot(ft_history['loss'], alpha=.3, color='#2ABC3D', linestyle='--')\n",
    "plt.plot(ft_history['val_loss'], label='Fine Tuning', alpha=.8, color='#2ABC3D')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Categorical Crossentropy')\n",
    "plt.grid(alpha=.3)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.plot(tl_history['accuracy'],label = 'Training Accuracy' , alpha=.3, color='#4D61E2', linestyle='--')\n",
    "plt.plot(tl_history['val_accuracy'], label='Validation accuracy', alpha=.8, color='#4D61E2')\n",
    "plt.plot(ft_history['accuracy'], alpha=.3, color='#2ABC3D', linestyle='--')\n",
    "plt.plot(ft_history['val_accuracy'], label='Fine Tuning', alpha=.8, color='#2ABC3D')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Accuracy')\n",
    "plt.grid(alpha=.3)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
